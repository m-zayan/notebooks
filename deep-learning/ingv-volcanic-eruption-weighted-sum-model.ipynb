{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# !git clone https://github.com/m-zayan/ml_utils.git","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom copy import deepcopy\nfrom glob import glob\n\nfrom tqdm.notebook import tqdm_notebook as tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\n\nplt.style.use('ggplot')\n\nworking_dir = '../input/predict-volcanic-eruptions-ingv-oe/'","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_dir = glob(working_dir + 'train/*')\ntest_dir = glob(working_dir + 'test/*')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata = pd.read_csv(working_dir + 'train.csv')\nsample_submission = pd.read_csv(working_dir + 'sample_submission.csv')\n\nsample_submission.head(2)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   segment_id  time_to_eruption\n0  1000213997                 0\n1   100023368                 0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segment_id</th>\n      <th>time_to_eruption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000213997</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100023368</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":" # Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_nan_stat(_dir, _ord=None):\n    \n    def list_cusum(lst):\n    \n        out = []\n        tmp = []\n        k = 0\n\n        for i in range(0, len(lst)):\n\n            for j in range(k, i + 1):\n\n                tmp.append(lst[j])\n                k = j + 1\n\n\n            out.append(deepcopy(tmp))\n\n        return out\n\n\n\n    isna = {}\n    df_nan = {}\n    mn_size = 1e9\n    \n    for i in tqdm(range(0 , len(_dir))):\n\n        x = pd.read_csv(_dir[i])\n        mn_size = min(mn_size, len(x))\n        \n        df_nan[i] = (x.isna().sum().values == len(x)).astype('int')\n        \n        tmp = x.isna().sum()\n        \n        if i == 0:\n            \n            for col in x.keys():\n                \n                isna[col] = 0\n        \n        for col in tmp.keys():\n            \n            isna[col] += tmp[col]\n        \n    \n    keys = _ord\n    \n    if _ord is None:\n        \n        isna = [(j, i) for i, j in isna.items()]\n\n        isna.sort()\n\n        keys = [j for i,j in isna]\n    \n    else:\n        \n        isna = [(isna[keys[i]], keys[i]) for i in range(len(keys))]\n        \n    ckeys = list_cusum(keys)\n    \n    values = [i for i, j in isna]\n    values = np.array(values)\n    \n    cusum_nan = np.cumsum(values)\n    size = np.repeat(mn_size * len(_dir), 10)\n\n    worst_case_size = size - cusum_nan\n    worst_case_size[worst_case_size < 0] = 0\n    \n    choices_size = list(zip(worst_case_size, ckeys))\n    \n    nan = np.array(list(df_nan.values()))\n    \n    return choices_size, nan # nan/sensor [from 1 to 10 in order] for each dataframe","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_choices, test_nan = is_nan_stat(test_dir, _ord=None)\n\n# features = np.where(test_nan.sum(axis=0) == 0)[0] + 1\n# features = list(map(lambda f: f'sensor_{f}', features))\n\n# print(features, '-- test size :', test_choices[1][0])\n\nfeatures = ['sensor_4', 'sensor_6']","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sampling "},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_id(_dir):\n    \n    return os.path.splitext(_dir)[0].split('/')[-1]\n\ndef get_traget(_dir):\n    \n    return metadata.query(f'segment_id == {get_id(_dir)}').values[0, 1]\n\ndef get_sample(_dir, sample_size=10, typ='train', seed=None):\n    \n    sample = None\n    skip_counts = 0\n    \n    seg_id = []\n    \n    for i in tqdm(range(len(_dir))):\n        \n        if seed:\n            seed += i\n        \n        x = pd.read_csv(_dir[i])[features].dropna()\n                \n        if len(x) < sample_size:\n            \n            if typ == 'test':\n                \n                raise ValueError(f'len(x) < sample_size, len(x) = {len(x)}, sample_size = {sample_size}, check features choice (nan)')\n            \n            else:\n                \n                skip_counts +=1\n                \n        x = x.sample(n=sample_size, random_state=seed)\n        \n        _id = get_id(_dir[i])\n        _id = [_id] * len(x)\n        \n        seg_id +=_id\n\n        if typ == 'train':\n            \n            y = get_traget(_dir[i])\n        \n        if i == 0:\n            \n            sample = x\n            \n            if typ == 'train':\n                \n                sample['target'] = [y] * len(x)\n            \n        else:\n            \n            tmp = x\n            \n            if typ == 'train':\n                \n                tmp['target'] = [y] * len(x)\n            \n            sample = pd.concat([sample, tmp], axis=0)\n    \n    sample.insert(loc=0, column='segment_id', value=seg_id)\n    sample.reset_index(drop=True, inplace=True)\n    \n    counts = len(_dir) - skip_counts\n    \n    return sample, counts","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_size = 1000\nseed = 1\n\ntest, _ = get_sample(_dir=test_dir, sample_size=sample_size, typ='test', seed=seed)\ntrain, counts = get_sample(_dir=train_dir, sample_size=sample_size, typ='train', seed=seed)","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=4520.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d74deb7d3944ba99f3bb798e9953406"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=4431.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d959d943f10544f5beba2d538fd84337"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('valid sample :', len(np.unique(test['segment_id'])) == len(test_dir))","execution_count":8,"outputs":[{"output_type":"stream","text":"valid sample : True\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{},"cell_type":"markdown","source":"$minimize : \\frac{1}{m} \\sum_{i=0}^{m} \\ (\\hat{y} * scale - y)^2$\n\n> $where: \\hat{y} = w_0 * d_0 + w_1 * d_1 + .... + w_k * d_k$\n\n> $subject \\ to: 0 \\leq w_j \\leq 1$ ---> (Could be converted into implicit constraints using sigmoid function)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def standardize(x):\n    \n    return (x - x.mean(axis=0)) / x.std(axis=0)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.to_numpy().reshape(counts, sample_size, 4)\nY = X[:, 0, -1, None].astype('float32')\n\nX = X[:, :, 1:-1].astype('float32')\n\nx_test = test.to_numpy().reshape(len(test_dir), sample_size, 3)\nseg_id = x_test[:, 0, 0]\n\nx_test = x_test[:, :, 1:].astype('float32')\n\nstandardized = standardize(X)\nstandardized_test = standardize(x_test)\n\nprint(X.shape)\nprint(Y.shape)\n\nprint('\\ntest shape : ', x_test.shape)\n\n# x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.1)\n\n# print(x_train.shape)\n# print(x_val.shape)","execution_count":10,"outputs":[{"output_type":"stream","text":"(4431, 1000, 2)\n(4431, 1)\n\ntest shape :  (4520, 1000, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"offset = 1e3\nscale = 1e6\nstep = 0.1\n\nmx = (train['target'].max() + offset) / scale\n\ndurations_dist = np.arange(1 , mx, step=step).astype('float32')\ndurations_dist = durations_dist[None, :]\n\ndist_size = durations_dist.shape[-1]\n\nprint('shape : ', durations_dist.shape)","execution_count":11,"outputs":[{"output_type":"stream","text":"shape :  (1, 481)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class WeightedSum(tf.keras.layers.Layer):\n    \n    def call(self, inputs):\n        \n        out = K.sum(inputs * durations_dist, axis=-1)\n        out = out[:, None]\n        \n        return out","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input(shape=[sample_size, 2])\n\nconv1d = Conv1D(filters=1, kernel_size=sample_size-1, activation='relu')(inputs)\n\nbatch_norm = BatchNormalization()(conv1d)\n\nlstm = LSTM(units=1, activation='tanh', return_sequences=True)(batch_norm)\nlstm = LSTM(units=dist_size, activation='sigmoid')(lstm) # weights\n\ndropout = Dropout(0.2)(lstm)\n\noutputs = WeightedSum()(dropout)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.summary()","execution_count":14,"outputs":[{"output_type":"stream","text":"Model: \"functional_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 1000, 2)]         0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 2, 1)              1999      \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 2, 1)              4         \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 2, 1)              12        \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 481)               929292    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 481)               0         \n_________________________________________________________________\nweighted_sum_1 (WeightedSum) (None, 1)                 0         \n=================================================================\nTotal params: 931,307\nTrainable params: 931,305\nNon-trainable params: 2\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mse_loss(y_true, y_pred):\n    \n    loss = (y_pred - (y_true / scale)) ** 2\n    \n    return K.mean(loss)\n    \ndef metrice(y_true, y_pred):\n    \n    msa = K.abs((y_pred * scale - y_true))\n    \n    return K.mean(msa)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer=opt, loss=mse_loss, metrics=metrice)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X, Y, steps_per_epoch=256, epochs=100)","execution_count":17,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n256/256 [==============================] - 2s 9ms/step - loss: 337814.1562 - metrice: 312008224.0000\nEpoch 2/100\n256/256 [==============================] - 2s 9ms/step - loss: 6571.4839 - metrice: 78723776.0000\nEpoch 3/100\n256/256 [==============================] - 3s 10ms/step - loss: 2529.6636 - metrice: 48058184.0000\nEpoch 4/100\n256/256 [==============================] - 2s 9ms/step - loss: 1293.5247 - metrice: 33061938.0000\nEpoch 5/100\n256/256 [==============================] - 2s 9ms/step - loss: 788.4263 - metrice: 24592442.0000\nEpoch 6/100\n256/256 [==============================] - 2s 9ms/step - loss: 527.5787 - metrice: 19128176.0000\nEpoch 7/100\n256/256 [==============================] - 3s 10ms/step - loss: 378.9496 - metrice: 16066570.0000\nEpoch 8/100\n256/256 [==============================] - 3s 11ms/step - loss: 301.5926 - metrice: 14316791.0000\nEpoch 9/100\n256/256 [==============================] - 3s 13ms/step - loss: 254.1574 - metrice: 13293148.0000\nEpoch 10/100\n256/256 [==============================] - 2s 9ms/step - loss: 217.0477 - metrice: 12422518.0000\nEpoch 11/100\n256/256 [==============================] - 2s 9ms/step - loss: 203.0572 - metrice: 12175714.0000\nEpoch 12/100\n256/256 [==============================] - 3s 11ms/step - loss: 186.6717 - metrice: 11694225.0000\nEpoch 13/100\n256/256 [==============================] - 2s 9ms/step - loss: 186.1541 - metrice: 11730126.0000\nEpoch 14/100\n256/256 [==============================] - 2s 9ms/step - loss: 176.1101 - metrice: 11427723.0000\nEpoch 15/100\n256/256 [==============================] - 2s 9ms/step - loss: 175.6155 - metrice: 11466302.0000\nEpoch 16/100\n256/256 [==============================] - 3s 10ms/step - loss: 173.0458 - metrice: 11283918.0000\nEpoch 17/100\n256/256 [==============================] - 2s 9ms/step - loss: 170.6392 - metrice: 11224275.0000\nEpoch 18/100\n256/256 [==============================] - 2s 9ms/step - loss: 167.2001 - metrice: 11094225.0000\nEpoch 19/100\n256/256 [==============================] - 2s 9ms/step - loss: 165.4921 - metrice: 11021653.0000\nEpoch 20/100\n256/256 [==============================] - 2s 9ms/step - loss: 160.8787 - metrice: 10781809.0000\nEpoch 21/100\n256/256 [==============================] - 3s 10ms/step - loss: 158.4962 - metrice: 10740293.0000\nEpoch 22/100\n256/256 [==============================] - 3s 11ms/step - loss: 158.5421 - metrice: 10659908.0000\nEpoch 23/100\n256/256 [==============================] - 2s 9ms/step - loss: 156.1082 - metrice: 10544500.0000\nEpoch 24/100\n256/256 [==============================] - 2s 9ms/step - loss: 150.1364 - metrice: 10320986.0000\nEpoch 25/100\n256/256 [==============================] - 3s 10ms/step - loss: 146.0470 - metrice: 10112949.0000\nEpoch 26/100\n256/256 [==============================] - 2s 9ms/step - loss: 146.0057 - metrice: 10022959.0000\nEpoch 27/100\n256/256 [==============================] - 2s 9ms/step - loss: 143.7591 - metrice: 9967170.0000\nEpoch 28/100\n256/256 [==============================] - 2s 9ms/step - loss: 145.0018 - metrice: 9988006.0000\nEpoch 29/100\n256/256 [==============================] - 2s 9ms/step - loss: 142.1584 - metrice: 9869966.0000\nEpoch 30/100\n256/256 [==============================] - 3s 10ms/step - loss: 136.9802 - metrice: 9612906.0000\nEpoch 31/100\n256/256 [==============================] - 2s 9ms/step - loss: 135.1028 - metrice: 9516096.0000\nEpoch 32/100\n256/256 [==============================] - 2s 9ms/step - loss: 132.6656 - metrice: 9387365.0000\nEpoch 33/100\n256/256 [==============================] - 3s 11ms/step - loss: 135.7239 - metrice: 9477482.0000\nEpoch 34/100\n256/256 [==============================] - 2s 10ms/step - loss: 129.8782 - metrice: 9244810.0000\nEpoch 35/100\n256/256 [==============================] - 4s 15ms/step - loss: 128.0275 - metrice: 9148215.0000\nEpoch 36/100\n256/256 [==============================] - 2s 9ms/step - loss: 132.3572 - metrice: 9336041.0000\nEpoch 37/100\n256/256 [==============================] - 2s 9ms/step - loss: 133.0255 - metrice: 9350775.0000\nEpoch 38/100\n256/256 [==============================] - 3s 10ms/step - loss: 132.7731 - metrice: 9332846.0000\nEpoch 39/100\n256/256 [==============================] - 2s 9ms/step - loss: 129.9590 - metrice: 9268140.0000\nEpoch 40/100\n256/256 [==============================] - 2s 9ms/step - loss: 128.3548 - metrice: 9189066.0000\nEpoch 41/100\n256/256 [==============================] - 2s 9ms/step - loss: 125.6243 - metrice: 9059316.0000\nEpoch 42/100\n256/256 [==============================] - 2s 8ms/step - loss: 126.5318 - metrice: 9070923.0000\nEpoch 43/100\n256/256 [==============================] - 3s 11ms/step - loss: 120.3521 - metrice: 8828823.0000\nEpoch 44/100\n256/256 [==============================] - 2s 9ms/step - loss: 121.0378 - metrice: 8816030.0000\nEpoch 45/100\n256/256 [==============================] - 2s 9ms/step - loss: 123.9802 - metrice: 8942322.0000\nEpoch 46/100\n256/256 [==============================] - 2s 9ms/step - loss: 120.7257 - metrice: 8832933.0000\nEpoch 47/100\n256/256 [==============================] - 2s 9ms/step - loss: 120.2596 - metrice: 8798401.0000\nEpoch 48/100\n256/256 [==============================] - 3s 13ms/step - loss: 119.9906 - metrice: 8817912.0000\nEpoch 49/100\n256/256 [==============================] - 2s 9ms/step - loss: 120.8690 - metrice: 8836739.0000\nEpoch 50/100\n256/256 [==============================] - 2s 9ms/step - loss: 120.5195 - metrice: 8789214.0000\nEpoch 51/100\n256/256 [==============================] - 2s 9ms/step - loss: 121.3830 - metrice: 8851649.0000\nEpoch 52/100\n256/256 [==============================] - 3s 10ms/step - loss: 117.6337 - metrice: 8656219.0000\nEpoch 53/100\n256/256 [==============================] - 2s 8ms/step - loss: 120.6177 - metrice: 8798827.0000\nEpoch 54/100\n256/256 [==============================] - 2s 8ms/step - loss: 119.1917 - metrice: 8674692.0000\nEpoch 55/100\n256/256 [==============================] - 2s 8ms/step - loss: 119.1425 - metrice: 8726313.0000\nEpoch 56/100\n256/256 [==============================] - 2s 9ms/step - loss: 117.4232 - metrice: 8639962.0000\nEpoch 57/100\n256/256 [==============================] - 3s 10ms/step - loss: 115.5800 - metrice: 8611330.0000\nEpoch 58/100\n256/256 [==============================] - 3s 11ms/step - loss: 118.2505 - metrice: 8657098.0000\nEpoch 59/100\n256/256 [==============================] - 3s 10ms/step - loss: 120.1672 - metrice: 8846161.0000\nEpoch 60/100\n256/256 [==============================] - 2s 9ms/step - loss: 118.1964 - metrice: 8715501.0000\nEpoch 61/100\n256/256 [==============================] - 3s 13ms/step - loss: 122.0657 - metrice: 8830855.0000\nEpoch 62/100\n256/256 [==============================] - 3s 10ms/step - loss: 120.9582 - metrice: 8779443.0000\nEpoch 63/100\n256/256 [==============================] - 2s 9ms/step - loss: 119.8142 - metrice: 8783513.0000\nEpoch 64/100\n256/256 [==============================] - 2s 9ms/step - loss: 119.5867 - metrice: 8720828.0000\nEpoch 65/100\n256/256 [==============================] - 2s 9ms/step - loss: 116.5645 - metrice: 8622285.0000\nEpoch 66/100\n256/256 [==============================] - 2s 10ms/step - loss: 116.1971 - metrice: 8536034.0000\nEpoch 67/100\n256/256 [==============================] - 2s 9ms/step - loss: 116.7949 - metrice: 8610338.0000\nEpoch 68/100\n256/256 [==============================] - 2s 9ms/step - loss: 110.9804 - metrice: 8360455.5000\nEpoch 69/100\n256/256 [==============================] - 2s 9ms/step - loss: 113.5398 - metrice: 8430841.0000\nEpoch 70/100\n256/256 [==============================] - 3s 10ms/step - loss: 113.8763 - metrice: 8482672.0000\nEpoch 71/100\n256/256 [==============================] - 2s 9ms/step - loss: 115.8154 - metrice: 8541289.0000\nEpoch 72/100\n256/256 [==============================] - 2s 9ms/step - loss: 114.1914 - metrice: 8467657.0000\nEpoch 73/100\n256/256 [==============================] - 2s 9ms/step - loss: 115.5756 - metrice: 8517558.0000\nEpoch 74/100\n256/256 [==============================] - 2s 9ms/step - loss: 111.9300 - metrice: 8358183.5000\nEpoch 75/100\n","name":"stdout"},{"output_type":"stream","text":"256/256 [==============================] - 3s 13ms/step - loss: 114.1479 - metrice: 8459442.0000\nEpoch 76/100\n256/256 [==============================] - 2s 9ms/step - loss: 107.9456 - metrice: 8205799.5000\nEpoch 77/100\n256/256 [==============================] - 2s 9ms/step - loss: 115.6933 - metrice: 8505994.0000\nEpoch 78/100\n256/256 [==============================] - 2s 9ms/step - loss: 115.0198 - metrice: 8519604.0000\nEpoch 79/100\n256/256 [==============================] - 3s 10ms/step - loss: 113.2116 - metrice: 8470868.0000\nEpoch 80/100\n256/256 [==============================] - 2s 9ms/step - loss: 114.9055 - metrice: 8495590.0000\nEpoch 81/100\n256/256 [==============================] - 2s 9ms/step - loss: 109.3242 - metrice: 8244464.0000\nEpoch 82/100\n256/256 [==============================] - 3s 11ms/step - loss: 114.8102 - metrice: 8539638.0000\nEpoch 83/100\n256/256 [==============================] - 2s 9ms/step - loss: 112.1624 - metrice: 8398414.0000\nEpoch 84/100\n256/256 [==============================] - 3s 12ms/step - loss: 111.4087 - metrice: 8332420.5000\nEpoch 85/100\n256/256 [==============================] - 2s 10ms/step - loss: 110.3906 - metrice: 8265357.0000\nEpoch 86/100\n256/256 [==============================] - 2s 10ms/step - loss: 110.1878 - metrice: 8274782.5000\nEpoch 87/100\n256/256 [==============================] - 3s 10ms/step - loss: 108.6014 - metrice: 8248163.5000\nEpoch 88/100\n256/256 [==============================] - 3s 12ms/step - loss: 109.3689 - metrice: 8245266.5000\nEpoch 89/100\n256/256 [==============================] - 2s 9ms/step - loss: 109.9962 - metrice: 8298931.5000\nEpoch 90/100\n256/256 [==============================] - 2s 9ms/step - loss: 106.5736 - metrice: 8144267.0000\nEpoch 91/100\n256/256 [==============================] - 2s 9ms/step - loss: 109.7633 - metrice: 8290737.5000\nEpoch 92/100\n256/256 [==============================] - 3s 10ms/step - loss: 109.3270 - metrice: 8235226.0000\nEpoch 93/100\n256/256 [==============================] - 2s 9ms/step - loss: 108.2263 - metrice: 8211158.0000\nEpoch 94/100\n256/256 [==============================] - 2s 9ms/step - loss: 109.7578 - metrice: 8239647.5000\nEpoch 95/100\n256/256 [==============================] - 2s 9ms/step - loss: 107.5370 - metrice: 8125723.5000\nEpoch 96/100\n256/256 [==============================] - 2s 9ms/step - loss: 105.8178 - metrice: 8119256.5000\nEpoch 97/100\n124/256 [=============>................] - 1s 10ms/step - loss: 111.5040 - metrice: 8363230.0000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = model.predict(x_test)\ny_test *= scale","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.min(), y_test.max()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"(15095701.0, 35926080.0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = {}\n\nsubmission['segment_id'] = seg_id.squeeze()\nsubmission['time_to_eruption'] = y_test.squeeze()\n\nsubmission = pd.DataFrame(submission)\n\nsubmission.to_csv('submission.csv', encoding='utf-8', index=False)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(2)","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"   segment_id  time_to_eruption\n0  1290851559        26189702.0\n1   543483467        25291820.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segment_id</th>\n      <th>time_to_eruption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1290851559</td>\n      <td>26189702.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>543483467</td>\n      <td>25291820.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}