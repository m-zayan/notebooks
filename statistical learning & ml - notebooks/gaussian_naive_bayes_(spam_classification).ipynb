{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gaussian_naive_bayes (spam classification).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uPc8Fw-C8T3"
      },
      "source": [
        "# Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkxxmKX4lVKY",
        "outputId": "168b3e37-b53e-406b-eb83-840d864cb792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "!git clone https://github.com/m-zayan/ml_utils.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ml_utils'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 15 (delta 1), reused 11 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (15/15), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJNLXWillWtD"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.insert(0, './ml_utils')\n",
        "\n",
        "from ml_utils.requests_utils.data_request import Writer\n",
        "\n",
        "url = 'https://datahub.io/machine-learning/spambase/r/spambase.csv'\n",
        "fname = 'spambase.csv'\n",
        "\n",
        "Writer.download_from_url(url, to_path=f'./{fname}', chunk_size=1024)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DQEFPGT4bDg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Used for measuring, how accurate the implementation is.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB as sklearn_gaussian_nb \n",
        "from sklearn.metrics import f1_score as sk_f1_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_XtLbcuHiRI"
      },
      "source": [
        "# F1 Score Metrice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY5LjSs6DiMG"
      },
      "source": [
        "def f1_score(y_true, y_pred, average='none'):\n",
        "\n",
        "\n",
        "  if average == 'marco':\n",
        "\n",
        "    classes = np.unique(y_true)\n",
        "    tp = np.zeros((len(classes, )))\n",
        "    fp = np.zeros((len(classes, ))) \n",
        "    fn = np.zeros((len(classes, )))\n",
        "       \n",
        "    for i in len(classes):\n",
        "      \n",
        "      y_i = classes[i]\n",
        "      \n",
        "      true = (y_true == y_i)\n",
        "      pred = (pred == y_i)\n",
        "\n",
        "      tp[i] = (true * pred).sum()\n",
        "      fp[i] = ((1-true) * pred).sum()\n",
        "      fn[i] = (true * (1-pred)).sum()\n",
        "\n",
        "      \n",
        "    p = (tp / (tp + fp).clip(1e-7)).mean()\n",
        "    r = (tp / (tp + fn).clip(1e-7)).mean()\n",
        "\n",
        "    f1 = 2.0 * p * r / (p + r).clip(1e-7)\n",
        "  \n",
        "  else:\n",
        "\n",
        "    tp = (y_true * y_pred).sum()\n",
        "    fp = ((1 - y_true) * y_pred).sum()\n",
        "    fn = (y_true * (1 - y_pred)).sum()\n",
        "\n",
        "    p = tp / (tp + fp).clip(1e-7)\n",
        "    r = tp / (tp + fn).clip(1e-7)\n",
        "\n",
        "    f1 = 2.0 * p * r / (p + r).clip(1e-7)\n",
        "  \n",
        "  return f1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq2YKQymC26-"
      },
      "source": [
        "# Model Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw0WL6Su5XdO"
      },
      "source": [
        "class GaussianNB:\n",
        "  \n",
        "  def __init__(self):\n",
        "\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "    self.params = None\n",
        "  \n",
        "  def __initialization__(self, x , y):\n",
        "\n",
        "    classes, count = np.unique(y, return_counts=True)\n",
        "    \n",
        "    n_samples, n_features = x.shape\n",
        "    n_classes = len(classes)\n",
        "\n",
        "    mean = np.zeros((n_classes,n_features))\n",
        "    sigma = np.zeros((n_classes, n_features))\n",
        "\n",
        "    prior = count / n_samples\n",
        "\n",
        "    self.params = {'mean':mean,\n",
        "                  'sigma':sigma,\n",
        "                  'prior':prior, \n",
        "                  'classes':classes , \n",
        "                  'count':count,\n",
        "                  'n_classes':n_classes,\n",
        "                  'n_samples':n_samples}\n",
        "  \n",
        "  def fit(self, x, y):\n",
        "\n",
        "    self.__initialization__(x, y)\n",
        "    \n",
        "    mean  = self.params['mean']\n",
        "    sigma = self.params['sigma']\n",
        "\n",
        "    prior = self.params['prior']\n",
        "\n",
        "    classes   = self.params['classes']\n",
        "\n",
        "    n_samples = self.params['n_samples']\n",
        "    n_classes = self.params['n_classes']\n",
        "\n",
        "    for i in range(n_classes):\n",
        "      \n",
        "      y_i = classes[i]\n",
        "      x_i = x[y == y_i]\n",
        "\n",
        "      mean[i] = x_i.mean(axis=0)\n",
        "      sigma[i] = x_i.var(axis=0)\n",
        "\n",
        "    self.params['mean'] = mean\n",
        "    self.params['sigma'] = sigma\n",
        "\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "    print(('prior :',prior, 'classes' ,classes, 'n_samples:',n_samples))\n",
        "  \n",
        "  def __joint_log_likelihood__(self, X):\n",
        "  \n",
        "    joint_log_likelihood = []\n",
        "    \n",
        "    classes = self.params['classes']\n",
        "    \n",
        "    prior = self.params['prior']\n",
        "    mean = self.params['mean']\n",
        "    sigma = self.params['sigma']\n",
        "    \n",
        "    for i in range(len(classes)):\n",
        "\n",
        "      joint_i = np.log(prior[i])\n",
        "      n_ij = -0.5 * np.sum(np.log(2. * np.pi * sigma[i, :]))\n",
        "      n_ij -= 0.5 * np.sum(((X - mean[i, :]) **2 ) / sigma[i, :], axis=1)\n",
        "      \n",
        "      joint_log_likelihood.append(joint_i + n_ij)\n",
        "\n",
        "    joint_log_likelihood = np.array(joint_log_likelihood).T\n",
        "\n",
        "    return joint_log_likelihood\n",
        "  \n",
        "\n",
        "  def predict(self, x_test):\n",
        "  \n",
        "    classes = self.params['classes']\n",
        "    jll = self.__joint_log_likelihood__(x_test)\n",
        "    \n",
        "    return classes[np.argmax(jll, axis=1)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKbnZRVqH95F"
      },
      "source": [
        "# Split dataset to Train set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7HqHzqyIG5D",
        "outputId": "8a9a5801-9fa6-44c4-c274-357daa790291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "spam_data = pd.read_csv('./spambase.csv')\n",
        "\n",
        "X, Y = spam_data.drop(['class'], axis=1).to_numpy() , spam_data['class'].to_numpy()\n",
        "\n",
        "x_train ,x_test ,y_train, y_test = train_test_split(X, Y, test_size=0.2 , random_state = 42)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3680, 57)\n",
            "(921, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45bQh-1q6h5T"
      },
      "source": [
        "# Test Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpTvbDBg69zM",
        "outputId": "eeb9fbad-cf81-483d-b1b1-03d02061980b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gnb = GaussianNB()\n",
        "\n",
        "gnb.fit(x_train, y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('prior :', array([0.61331522, 0.38668478]), 'classes', array([0, 1]), 'n_samples:', 3680)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Em_S-B7ZZU",
        "outputId": "425064dc-f4ee-4ecc-a164-ec38233174a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "prediction = gnb.predict(x_test)\n",
        "\n",
        "print('F1 Score :', f1_score(y_test, prediction))\n",
        "print('Sklearn F1 Score :' , sk_f1_score(y_test, prediction))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score : 0.8169642857142857\n",
            "Sklearn F1 Score : 0.8169642857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU9P0yti9HXw"
      },
      "source": [
        "# Using Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBDFRikD8GPa",
        "outputId": "326ea9d9-af81-4567-dc56-d2938c28404a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s_gnb = sklearn_gaussian_nb()\n",
        "\n",
        "s_gnb.fit(x_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwgeVHtM9ocX",
        "outputId": "7026af7d-fcf9-48ac-9f93-1f884fe6355c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "prediction = s_gnb.predict(x_test)\n",
        "\n",
        "print('F1 Score :', f1_score(y_test, prediction))\n",
        "print('Sklearn F1 Score :' , sk_f1_score(y_test, prediction))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score : 0.8172757475083057\n",
            "Sklearn F1 Score : 0.8172757475083057\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}